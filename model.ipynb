{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd09e45ca6d2f9a632adb471d6a7900c6b597dba7cec4c13cfc3bc8479688782778",
   "display_name": "Python 3.7.7 64-bit ('MITRE_modeling': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Training and Evaluation\n",
    "This is the final notebook for the training and evaluation of the BERT-like architecture, built on top of TensorFlow examples and tutorials. It will use the training data from the vectorized_samples directory containing 3.1 GB of 5000 .npy fizes of vectorized MalDroid analysis. The samples are broken up into categories as follows:\n",
    "* Adware: 812 (~15.8%)\n",
    "* Banking: 1438 (~28%)\n",
    "* SMS: 1442 (~28.06%)\n",
    "* Riskware: 1447 (~28.16%)\n",
    "## Objectives\n",
    "1. Set up input pipeline to read directly from notebook filesystem\n",
    "2. Implement pipeline optimizations outlined in the TensorFlow docs\n",
    "3. Define the BERT from TensorFlow docs, adding head classifier layer(s)\n",
    "4. Write the training loop \n",
    "5. Implement logging of associated metrics and save checkpoints\n",
    "6. Train and evaluate (be sure to properly initalize weights)\n",
    "## Improvements (if not included)\n",
    "* Better weight initalization\n",
    "* Support for TPUs\n",
    "* Support for mixed precision\n",
    "* Attention output and plotting\n",
    "* Hyperparameter tuning\n",
    "* Larger-sized model\n",
    "* Trimmed vocab size\n",
    "* Larger sample size\n",
    "* Profile the input pipeline to improve performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\nEager execution: True\nNum GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "# confirm tensorflow is using GPU:\n",
    "print(tf.__version__)\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import random\n",
    "random.seed(42)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup mixed precision for GPU\n",
    "# mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# setup mixed precision for TPU\n",
    "# mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "# see https://www.tensorflow.org/guide/mixed_precision#summary for mixed precision guidelines"
   ]
  },
  {
   "source": [
    "## Input pipeline\n",
    "The pipeline needs to meet the following criteria:\n",
    "* Avoid loading the whole dataset into memory\n",
    "* Apply padding to the samples (max_len: 2783755, trimmed to 5039: 1283945), pads to max len in batch as configured\n",
    "* Implement a fix for unbalanced data\n",
    "* Batch the samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max length of samples\n",
    "\n",
    "# max_sample_len = 0\n",
    "# for mal_class in os.listdir('vectorized_samples'):\n",
    "#     parent_path = 'vectorized_samples/' + mal_class + '/'\n",
    "#     for sample_path in os.listdir(parent_path):\n",
    "#         len_list.append(np.load(parent_path + sample_path).size)\n",
    "#         if sample_len > max_sample_len:\n",
    "#             max_sample_len = sample_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of sample lengths for analysis\n",
    "\n",
    "# len_list = []\n",
    "# for mal_class in os.listdir('vectorized_samples'):\n",
    "#     parent_path = 'vectorized_samples/' + mal_class + '/'\n",
    "#     for sample_path in os.listdir(parent_path):\n",
    "#         len_list.append(np.load(parent_path + sample_path).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = sns.boxplot(x=len_list)"
   ]
  },
  {
   "source": [
    "Boxplot of sample lengths reveals a large amount of outliers, it would be benificial to model performance to limit the max length of the dataset. We have 5,139 samples therefore we could cut the 100 or so greatest lengths. The results of this process shown below yield a max sample length of 1283945, a significant decrease from 2.78 million. This is a viable solution if training cost proves unmanageable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_list.sort(reverse=True)\n",
    "# len_list = len_list[100:]\n",
    "# max_sample_len_trimmed = len_list[0]\n",
    "# print(max_sample_len_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path_list = glob('vectorized_samples/*/*.npy')\n",
    "\n",
    "# shuffling the samples now so the runtime does not have to deal with maintaining a large buffer\n",
    "random.shuffle(sample_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts labels to categorical ints as follows:\n",
    "# adware: 0\n",
    "# banking: 1\n",
    "# sms: 2\n",
    "# riskware: 3\n",
    "\n",
    "def process_path(file_paths):\n",
    "    for file_path in file_paths:\n",
    "        label = tf.strings.split(file_path, os.path.sep)[-2]\n",
    "        if label == 'adware':\n",
    "            label = 0\n",
    "        elif label == 'banking':\n",
    "            label = 1\n",
    "        elif label == 'sms':\n",
    "            label = 2\n",
    "        elif label == 'riskware':\n",
    "            label = 3\n",
    "        sample = np.load(file_path)\n",
    "        yield sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates a dataset that does not account for class imbalance\n",
    "\n",
    "# data = tf.data.Dataset.from_generator(process_path, args=[sample_path_list], output_types=(tf.int32, tf.int32), output_shapes=((None,), ()))"
   ]
  },
  {
   "source": [
    "### Class Imbalance\n",
    "Analysis of vectorized samples shows that Adware is signifigantly underrepresented, making up around 18% compared to around 28% from each other class. To account for this, we will oversample Adware. Some more advanced techniques like class weighting could be more effective but cannot be implemented due to time constraints and potential training overhead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not the most efficient but it is useable and is only run once\n",
    "\n",
    "adware_paths = []\n",
    "banking_paths = []\n",
    "sms_paths = []\n",
    "riskware_paths = []\n",
    "\n",
    "for path in sample_path_list:\n",
    "    label = tf.strings.split(path, os.path.sep)[-2]\n",
    "    if label == 'adware':\n",
    "        adware_paths.append(path)\n",
    "    elif label == 'banking':\n",
    "        banking_paths.append(path)\n",
    "    elif label == 'sms':\n",
    "        sms_paths.append(path)\n",
    "    elif label == 'riskware':\n",
    "        riskware_paths.append(path)\n",
    "\n",
    "# cleaning up sample_path_list\n",
    "sample_path_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if memory becomes an issue consider dropping the precision of ints to 8, alteratively if more values are needed increase to 32. As it stands, these precisions are appropriate for their value ranges\n",
    "adware_data = tf.data.Dataset.from_generator(process_path, args=[adware_paths], output_types=(tf.int16, tf.int8), output_shapes=((None,), ()))\n",
    "\n",
    "banking_data = tf.data.Dataset.from_generator(process_path, args=[banking_paths], output_types=(tf.int16, tf.int8), output_shapes=((None,), ()))\n",
    "\n",
    "sms_data = tf.data.Dataset.from_generator(process_path, args=[sms_paths], output_types=(tf.int16, tf.int8), output_shapes=((None,), ()))\n",
    "\n",
    "riskware_data = tf.data.Dataset.from_generator(process_path, args=[riskware_paths], output_types=(tf.int16, tf.int8), output_shapes=((None,), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't panic, seed is for reproducible results\n",
    "oversamp_data = tf.data.experimental.sample_from_datasets([adware_data, banking_data, sms_data, riskware_data], weights=[0.25,0.25,0.25,0.25], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 250\n",
    "BATCH_SIZE = 32 # Reccomended by BERT paper, alt is 16\n",
    "DATASET_SIZE = 5139\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "def make_batches(dataset):\n",
    "    return (\n",
    "        dataset\n",
    "        .cache() # comment out if too memory intensive\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .repeat()\n",
    "        .padded_batch(BATCH_SIZE, padding_values=-1, drop_remainder=True) # constant padding size if necessary is 'padded_shapes=((2783760,), ())'; shape of padded tensor is selected as it is the max len of sample rounded to a multiple of 8 for max GPU performance\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "oversamp_data.shuffle(BUFFER_SIZE, seed=42, reshuffle_each_iteration=False)\n",
    "train_dataset = oversamp_data.take(train_size)\n",
    "test_dataset = oversamp_data.skip(train_size)\n",
    "val_dataset = test_dataset.skip(val_size)\n",
    "test_dataset = test_dataset.take(test_size)\n",
    "\n",
    "train_dataset = make_batches(train_dataset)\n",
    "test_dataset = make_batches(test_dataset)\n",
    "val_dataset = make_batches(val_dataset)"
   ]
  },
  {
   "source": [
    "## BERT Model\n",
    "Adapted from tutorials provided by TensorFlow (https://www.tensorflow.org/tutorials/text/transformer) on the transformer model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Positional Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "source": [
    "### Masking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "source": [
    "### Scaled Dot-Product Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "source": [
    "### Multi-Head Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "source": [
    "### Point-Wise Feed-Forward Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "source": [
    "### Encoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model), this is where attn weights would be output\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                            self.d_model)\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "source": [
    "### Model Declaration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, num_classes, rate=0.1):\n",
    "    # pe_input is the max_positional_encoding\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                             input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(num_classes, activation='softmax') # 4 is the number of classes\n",
    "\n",
    "  def call(self, inp, tar, training, enc_padding_mask,\n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    flatten_output = self.flatten(enc_output)  # (batch_size, inp_seq_len*d_model)\n",
    "\n",
    "    final_output = self.final_layer(flatten_output)  # (batch_size, num_classes)\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "source": [
    "### Hyperparameters\n",
    "Due to time and resource constraints, we will be using the values specified by the BERT paper (BERT_base). Better performance could be achieved by conducting through tuning on these values in this use case. Additionally, if training time becomes an issue this could be decreased to the criteria of BERT_small or BERT_medium. Details about these dimensions can be found in the BERT github readme (https://github.com/google-research/bert)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 12\n",
    "d_model = 768\n",
    "dff = 3072\n",
    "num_heads = 12\n",
    "dropout_rate = 0.1\n",
    "num_classes = 4"
   ]
  },
  {
   "source": [
    "### Optimizer\n",
    "Uses Adam with custom learning rate scheduler defined in original transformer paper (https://arxiv.org/abs/1706.03762)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "source": [
    "### Loss\n",
    "Some notes:\n",
    "* This assumes the output is not a single integer indicating the predicted class and is instead an array of len>2. If this is not the case, change to non-sparse\n",
    "* This also assumes that the output is a probability distribution (ie [0.1, 0.3, 0.6]) not a logit array (ie [0, 0, 1]). If this is not the case, pass from_logits=True\n",
    "* The reduction indicated by TF transformer tutorial is 'none', the default is AUTO (docs indicates this typically results in SUM). This calculates gradient updates independently for the loss with respect to each input in the batch and then apply (the composition of) them (https://datascience.stackexchange.com/questions/55151/differences-between-gradient-calculated-by-different-reduction-methods-in-pytorc). However, the TF transformer loss function calls reduce_sum on the loss to average it by the sum of the mask so it is likely this achieves the same effect as 'SUM' therefore auto is used\n",
    "* The TF transformer tutorial indicates the inclusion of a padding mask when calculating loss and metrics. I do not belive this is necessary in this use case as the tutorial assumes the desired output is a sequence of tokens\n",
    "#### If there are any issues with loss, these may be of some assistance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    return loss_object(real, pred)"
   ]
  },
  {
   "source": [
    "## Training, Checkpointing, and Evaluation Loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 157\n",
    "# This will train on approx 5,024 samples (with a batch size of 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int16), # tokens\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int8), # labels\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(input, label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = transformer(inp, tar_inp,\n",
    "                                 True,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "source": [
    "Portions of this page are reproduced from and/or modifications based on work created and shared by Google (https://developers.google.com/readme/policies) and used according to terms described in the Creative Commons 4.0 Attribution License (https://creativecommons.org/licenses/by/4.0/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}