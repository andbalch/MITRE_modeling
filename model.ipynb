{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Training and Evaluation\n",
    "This is the final notebook for the training and evaluation of the BERT-like architecture, built on top of TensorFlow examples and tutorials. It will use the training data from the vectorized_samples directory containing 3.1 GB of 5000 .npy fizes of vectorized MalDroid analysis. The samples are broken up into categories as follows:\n",
    "* Adware: 812\n",
    "* Banking: 1438\n",
    "* SMS: 1442\n",
    "* Riskware: 1447\n",
    "## Objectives\n",
    "1. Set up input pipeline to read directly from GitHub raw\n",
    "2. Implement pipeline optimizations outlined in the TensorFlow docs\n",
    "3. Define the BERT from TensorFlow docs, adding head classifier layer(s)\n",
    "4. Write the training loop \n",
    "5. Implement logging of associated metrics\n",
    "6. Train and evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Portions of this page are reproduced from and/or modifications based on work created and shared by Google (https://developers.google.com/readme/policies) and used according to terms described in the Creative Commons 4.0 Attribution License (https://creativecommons.org/licenses/by/4.0/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}